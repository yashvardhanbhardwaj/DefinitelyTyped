{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiment on open price for 100 features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "11OodL_I7AKNMpp-SBv_Om4VcOnDXncId",
      "authorship_tag": "ABX9TyPD9a+8ljUvf0Ro8PBrt/Q5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashvardhanbhardwaj/DefinitelyTyped/blob/master/code/experiment_on_open_price_for_100_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFcRxtOSKuV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50422635-284d-406a-b64c-a95e8ae685bc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/aapl.us.txt',sep=',', index_col='Date', parse_dates=['Date'], date_parser=dateparse).fillna(0)\n",
        "#plot close price\n",
        "#plt.figure(figsize=(10,6))\n",
        "# plt.grid(True)\n",
        "# plt.xlabel('Year')\n",
        "# plt.ylabel('Close Prices')\n",
        "# All months data of 2017 for Close price\n",
        "#data.tail()\n",
        "#plt.title('All months data of 2017 for Close price')\n",
        "#plt.plot(data.loc['2017-01-01':'2017-12-31']['Close'])\n",
        "#plt.figure()\n",
        "## Difference of close values for each date\n",
        "#plt.title('Difference of close values for each date')\n",
        "#plt.plot(np.diff(data.loc['2017-01-01':'2017-12-31']['Close']))\n",
        "#plt.figure()\n",
        "## Histogram for values\n",
        "#plt.title('Histogram for values of Close for each date')\n",
        "#plt.hist(np.diff(data.loc['2017-01-01':'2017-12-31']['Close']))\n",
        "## plt.title('Closing Price')\n",
        "## plt.show()\n",
        "#plt.figure(figsize=(10,6))\n",
        "## plt.grid(True)\n",
        "## plt.xlabel('Year')\n",
        "## plt.ylabel('Close Prices')\n",
        "## All close date in file\n",
        "#plt.title('All Close prices in file')\n",
        "#plt.plot(data['Close'])\n",
        "#plt.figure()\n",
        "## Difference of Close prices\n",
        "#plt.title('Difference of Close prices in file')\n",
        "#plt.plot(np.diff(data['Close']))\n",
        "#plt.figure()\n",
        "## Histogram for whole data\n",
        "#plt.title('Histogram for whole Close prices in file')\n",
        "#plt.hist(np.diff(data['Close']))\n",
        "#plt.figure()\n",
        "#df_close = data['Close']\n",
        "#df_close.plot(style='k.')\n",
        "#plt.title('Scatter plot of closing price')\n",
        "#plt.show()\n",
        "##data.shape\n",
        "## train, test = train_test_split(data, test_size=0.33)\n",
        "#data.head()\n",
        "df1=data.reset_index()['Open']\n",
        "#df1\n",
        "#plt.plot(df1)\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
        "#print(df1)\n",
        "training_size=int(len(df1)*0.67)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]\n",
        "training_size,test_size\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        " \n",
        " \n",
        "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
        "time_step = 100\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)\n",
        "#print(X_train.shape), print(y_train.shape)\n",
        "\n",
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
        "\n",
        "#X_train, X_test"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSS3pwF50pxL",
        "outputId": "34ce0312-70e5-4593-97ff-57690185e4ae"
      },
      "source": [
        "### Create the Stacked LSTM model\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "\r\n",
        "model=Sequential()\r\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\r\n",
        "model.add(LSTM(50,return_sequences=True))\r\n",
        "model.add(LSTM(50))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\r\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 50)           10400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 50)           20200     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFPPw5_P1Az7",
        "outputId": "5d8f40d0-a77b-4de5-e8f6-f2a42597c4b0"
      },
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "86/86 [==============================] - 23s 208ms/step - loss: 5.8692e-05 - val_loss: 0.0025\n",
            "Epoch 2/100\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 2.4805e-06 - val_loss: 0.0036\n",
            "Epoch 3/100\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 1.9951e-06 - val_loss: 0.0032\n",
            "Epoch 4/100\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 1.9112e-06 - val_loss: 0.0015\n",
            "Epoch 5/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 1.7520e-06 - val_loss: 0.0041\n",
            "Epoch 6/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 1.8804e-06 - val_loss: 0.0023\n",
            "Epoch 7/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 1.9264e-06 - val_loss: 0.0021\n",
            "Epoch 8/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 1.3849e-06 - val_loss: 0.0021\n",
            "Epoch 9/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 1.2040e-06 - val_loss: 9.1612e-04\n",
            "Epoch 10/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 1.4368e-06 - val_loss: 0.0024\n",
            "Epoch 11/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 1.3163e-06 - val_loss: 0.0016\n",
            "Epoch 12/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 1.2260e-06 - val_loss: 0.0020\n",
            "Epoch 13/100\n",
            "86/86 [==============================] - 16s 192ms/step - loss: 1.0583e-06 - val_loss: 0.0022\n",
            "Epoch 14/100\n",
            "86/86 [==============================] - 16s 192ms/step - loss: 1.3122e-06 - val_loss: 0.0025\n",
            "Epoch 15/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 1.0578e-06 - val_loss: 0.0012\n",
            "Epoch 16/100\n",
            "86/86 [==============================] - 17s 192ms/step - loss: 1.1832e-06 - val_loss: 0.0017\n",
            "Epoch 17/100\n",
            "86/86 [==============================] - 16s 192ms/step - loss: 1.0400e-06 - val_loss: 0.0021\n",
            "Epoch 18/100\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 1.1916e-06 - val_loss: 0.0014\n",
            "Epoch 19/100\n",
            "86/86 [==============================] - 16s 187ms/step - loss: 8.9753e-07 - val_loss: 0.0022\n",
            "Epoch 20/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 1.4020e-06 - val_loss: 0.0014\n",
            "Epoch 21/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 8.1792e-07 - val_loss: 8.1041e-04\n",
            "Epoch 22/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 8.5499e-07 - val_loss: 0.0019\n",
            "Epoch 23/100\n",
            "86/86 [==============================] - 16s 188ms/step - loss: 9.9071e-07 - val_loss: 7.6258e-04\n",
            "Epoch 24/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 1.1543e-06 - val_loss: 3.8839e-04\n",
            "Epoch 25/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 1.0577e-06 - val_loss: 0.0017\n",
            "Epoch 26/100\n",
            "86/86 [==============================] - 16s 187ms/step - loss: 7.2352e-07 - val_loss: 4.5011e-04\n",
            "Epoch 27/100\n",
            "86/86 [==============================] - 16s 187ms/step - loss: 9.6208e-07 - val_loss: 7.2691e-04\n",
            "Epoch 28/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 8.3644e-07 - val_loss: 7.4986e-04\n",
            "Epoch 29/100\n",
            "86/86 [==============================] - 16s 190ms/step - loss: 8.7199e-07 - val_loss: 3.4806e-04\n",
            "Epoch 30/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 8.3839e-07 - val_loss: 5.2632e-04\n",
            "Epoch 31/100\n",
            "86/86 [==============================] - 16s 192ms/step - loss: 8.2103e-07 - val_loss: 4.9445e-04\n",
            "Epoch 32/100\n",
            "86/86 [==============================] - 17s 196ms/step - loss: 6.2156e-07 - val_loss: 7.2597e-04\n",
            "Epoch 33/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 7.4944e-07 - val_loss: 9.1410e-04\n",
            "Epoch 34/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 5.4687e-07 - val_loss: 0.0015\n",
            "Epoch 35/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 6.7379e-07 - val_loss: 5.6148e-04\n",
            "Epoch 36/100\n",
            "86/86 [==============================] - 17s 196ms/step - loss: 6.3344e-07 - val_loss: 6.4820e-04\n",
            "Epoch 37/100\n",
            "86/86 [==============================] - 17s 197ms/step - loss: 5.9467e-07 - val_loss: 7.6327e-04\n",
            "Epoch 38/100\n",
            "86/86 [==============================] - 17s 196ms/step - loss: 4.9704e-07 - val_loss: 4.0726e-04\n",
            "Epoch 39/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 5.6481e-07 - val_loss: 7.2261e-04\n",
            "Epoch 40/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 5.9149e-07 - val_loss: 8.4877e-04\n",
            "Epoch 41/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 9.2847e-07 - val_loss: 9.3828e-04\n",
            "Epoch 42/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 5.9461e-07 - val_loss: 7.0638e-04\n",
            "Epoch 43/100\n",
            "86/86 [==============================] - 17s 197ms/step - loss: 5.8320e-07 - val_loss: 7.0610e-04\n",
            "Epoch 44/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 5.4938e-07 - val_loss: 3.2630e-04\n",
            "Epoch 45/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 7.2580e-07 - val_loss: 0.0018\n",
            "Epoch 46/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 7.6777e-07 - val_loss: 3.3115e-04\n",
            "Epoch 47/100\n",
            "86/86 [==============================] - 17s 192ms/step - loss: 6.2731e-07 - val_loss: 7.9876e-04\n",
            "Epoch 48/100\n",
            "86/86 [==============================] - 17s 196ms/step - loss: 5.6207e-07 - val_loss: 6.3298e-04\n",
            "Epoch 49/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 6.0172e-07 - val_loss: 5.4154e-04\n",
            "Epoch 50/100\n",
            "86/86 [==============================] - 17s 200ms/step - loss: 5.1859e-07 - val_loss: 2.5226e-04\n",
            "Epoch 51/100\n",
            "86/86 [==============================] - 17s 198ms/step - loss: 5.2371e-07 - val_loss: 3.9492e-04\n",
            "Epoch 52/100\n",
            "86/86 [==============================] - 17s 197ms/step - loss: 5.3116e-07 - val_loss: 0.0013\n",
            "Epoch 53/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 4.9271e-07 - val_loss: 3.4008e-04\n",
            "Epoch 54/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 4.2688e-07 - val_loss: 6.9137e-04\n",
            "Epoch 55/100\n",
            "86/86 [==============================] - 17s 192ms/step - loss: 4.0425e-07 - val_loss: 9.6763e-04\n",
            "Epoch 56/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 4.6254e-07 - val_loss: 0.0011\n",
            "Epoch 57/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 5.2963e-07 - val_loss: 4.9762e-04\n",
            "Epoch 58/100\n",
            "86/86 [==============================] - 17s 197ms/step - loss: 4.1573e-07 - val_loss: 3.7170e-04\n",
            "Epoch 59/100\n",
            "86/86 [==============================] - 17s 199ms/step - loss: 4.7869e-07 - val_loss: 6.1683e-04\n",
            "Epoch 60/100\n",
            "86/86 [==============================] - 17s 196ms/step - loss: 5.3186e-07 - val_loss: 2.4164e-04\n",
            "Epoch 61/100\n",
            "86/86 [==============================] - 17s 199ms/step - loss: 3.7715e-07 - val_loss: 4.9628e-04\n",
            "Epoch 62/100\n",
            "86/86 [==============================] - 17s 196ms/step - loss: 4.5547e-07 - val_loss: 5.7305e-04\n",
            "Epoch 63/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 4.3005e-07 - val_loss: 5.6731e-04\n",
            "Epoch 64/100\n",
            "86/86 [==============================] - 17s 203ms/step - loss: 4.7252e-07 - val_loss: 5.3954e-04\n",
            "Epoch 65/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 4.1549e-07 - val_loss: 2.0601e-04\n",
            "Epoch 66/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 3.7587e-07 - val_loss: 2.6628e-04\n",
            "Epoch 67/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 4.8444e-07 - val_loss: 5.5111e-04\n",
            "Epoch 68/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 3.5844e-07 - val_loss: 7.5245e-04\n",
            "Epoch 69/100\n",
            "86/86 [==============================] - 16s 191ms/step - loss: 4.2226e-07 - val_loss: 5.3218e-04\n",
            "Epoch 70/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 3.4475e-07 - val_loss: 1.8425e-04\n",
            "Epoch 71/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 6.9217e-07 - val_loss: 2.0068e-04\n",
            "Epoch 72/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 3.9139e-07 - val_loss: 3.1725e-04\n",
            "Epoch 73/100\n",
            "86/86 [==============================] - 16s 192ms/step - loss: 4.5665e-07 - val_loss: 3.6160e-04\n",
            "Epoch 74/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 3.6295e-07 - val_loss: 5.6758e-04\n",
            "Epoch 75/100\n",
            "86/86 [==============================] - 16s 192ms/step - loss: 3.4698e-07 - val_loss: 4.6525e-04\n",
            "Epoch 76/100\n",
            "86/86 [==============================] - 17s 193ms/step - loss: 4.5907e-07 - val_loss: 4.2379e-04\n",
            "Epoch 77/100\n",
            "86/86 [==============================] - 17s 195ms/step - loss: 3.2241e-07 - val_loss: 2.3600e-04\n",
            "Epoch 78/100\n",
            "86/86 [==============================] - 17s 194ms/step - loss: 4.0845e-07 - val_loss: 4.9644e-04\n",
            "Epoch 79/100\n",
            "86/86 [==============================] - 16s 189ms/step - loss: 3.5123e-07 - val_loss: 7.3112e-04\n",
            "Epoch 80/100\n",
            "86/86 [==============================] - 17s 192ms/step - loss: 3.9545e-07 - val_loss: 3.9282e-04\n",
            "Epoch 81/100\n",
            "86/86 [==============================] - 16s 186ms/step - loss: 2.9866e-07 - val_loss: 1.7958e-04\n",
            "Epoch 82/100\n",
            "86/86 [==============================] - 16s 185ms/step - loss: 3.8751e-07 - val_loss: 5.2918e-04\n",
            "Epoch 83/100\n",
            "86/86 [==============================] - 16s 185ms/step - loss: 4.5639e-07 - val_loss: 3.1533e-04\n",
            "Epoch 84/100\n",
            "86/86 [==============================] - 16s 186ms/step - loss: 3.0047e-07 - val_loss: 1.9602e-04\n",
            "Epoch 85/100\n",
            "86/86 [==============================] - 16s 185ms/step - loss: 4.4791e-07 - val_loss: 3.0222e-04\n",
            "Epoch 86/100\n",
            "21/86 [======>.......................] - ETA: 10s - loss: 3.8295e-07"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X76fHPuy70ff"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "### prediction and check performance metrics\r\n",
        "train_predict=model.predict(X_train)\r\n",
        "test_predict=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuv-iSJv8Yux"
      },
      "source": [
        "##Transformback to original form\r\n",
        "train_predict=scaler.inverse_transform(train_predict)\r\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lKJZ3Tr8ccM"
      },
      "source": [
        "import math \r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "math.sqrt(mean_squared_error(y_train,train_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI7NT1pB8jZG"
      },
      "source": [
        "### Test Data RMSE\r\n",
        "math.sqrt(mean_squared_error(ytest,test_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzEf2pH78nE9"
      },
      "source": [
        "### Plotting \r\n",
        "# shift train predictions for plotting\r\n",
        "look_back=100\r\n",
        "trainPredictPlot = np.empty_like(df1)\r\n",
        "trainPredictPlot[:, :] = np.nan\r\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\r\n",
        "# shift test predictions for plotting\r\n",
        "testPredictPlot = np.empty_like(df1)\r\n",
        "testPredictPlot[:, :] = np.nan\r\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\r\n",
        "# plot baseline and predictions\r\n",
        "plt.plot(scaler.inverse_transform(df1))\r\n",
        "plt.plot(trainPredictPlot)\r\n",
        "#plt.figure()\r\n",
        "plt.plot(testPredictPlot)\r\n",
        "#plt.figure()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWULSejQ8vG0"
      },
      "source": [
        "len(test_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmxAWoda8zSA"
      },
      "source": [
        "x_input=test_data[(len(test_data) - 100):].reshape(1,-1)\r\n",
        "x_input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SnqqZtd83P-"
      },
      "source": [
        "temp_input=list(x_input)\r\n",
        "temp_input=temp_input[0].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HplazH4M8806"
      },
      "source": [
        "# demonstrate prediction for next 10 days\r\n",
        "from numpy import array\r\n",
        "\r\n",
        "lst_output=[]\r\n",
        "n_steps=100\r\n",
        "i=0\r\n",
        "while(i<30):\r\n",
        "    \r\n",
        "    if(len(temp_input)>100):\r\n",
        "        #print(temp_input)\r\n",
        "        x_input=np.array(temp_input[1:])\r\n",
        "        print(\"{} day input {}\".format(i,x_input))\r\n",
        "        x_input=x_input.reshape(1,-1)\r\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\r\n",
        "        #print(x_input)\r\n",
        "        yhat = model.predict(x_input, verbose=0)\r\n",
        "        print(\"{} day output {}\".format(i,yhat))\r\n",
        "        temp_input.extend(yhat[0].tolist())\r\n",
        "        temp_input=temp_input[1:]\r\n",
        "        #print(temp_input)\r\n",
        "        lst_output.extend(yhat.tolist())\r\n",
        "        i=i+1\r\n",
        "    else:\r\n",
        "        x_input = x_input.reshape((1, n_steps,1))\r\n",
        "        yhat = model.predict(x_input, verbose=0)\r\n",
        "        print(yhat[0])\r\n",
        "        temp_input.extend(yhat[0].tolist())\r\n",
        "        print(len(temp_input))\r\n",
        "        lst_output.extend(yhat.tolist())\r\n",
        "        i=i+1\r\n",
        "  \r\n",
        "print(lst_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-nbgm9qBh_N"
      },
      "source": [
        "day_new=np.arange(1,101)\r\n",
        "day_pred=np.arange(101,131)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUuiJlDVBtjE"
      },
      "source": [
        "len(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyW6anZ9Bw7N"
      },
      "source": [
        "plt.plot(day_new,scaler.inverse_transform(df1[8264:]))\r\n",
        "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8X_V-WkCDPo"
      },
      "source": [
        "df3=df1.tolist()\r\n",
        "df3.extend(lst_output)\r\n",
        "plt.plot(df3[1200:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZVQUQxCKks"
      },
      "source": [
        "\r\n",
        "df3=scaler.inverse_transform(df3).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MLjPdaGCL-j"
      },
      "source": [
        "plt.plot(df3)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}